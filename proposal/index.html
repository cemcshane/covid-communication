<!doctype html>
<html>
    <head>
        <meta charset="utf-8">
        <title>COVID Communications - Project Proposal</title>

        <link rel="stylesheet" href="css/style.css">
    </head>
    <body>
        
        <h1>COVID Communications Project Proposal</h1>
        
        <h3>Basic Info</h3>
        <p>
            Covid Communications<br />
            Ben Tzudiker, 457993, bentzudiker@wustl.edu<br />
            Claire McShane, 464850, cemcshane@wustl.edu<br />
            Emma Baker, 450470, emma.baker@wustl.edu<br />
            <a href="https://github.com/cemcshane/covid-communication">https://github.com/cemcshane/covid-communication</a><br />
        </p>
        
        <h3>Background and Motivation</h3>
        <p>
            We are interested in studying the use of language in public-facing spheres as it relates to COVID-19 communications. Whether it be from elected officials, journalists or other sources there is an intended audience which defines the posture of the writer or speaker. We want to study the sentiment analysis of these different perspectives to get a greater understanding of how the texture of language itself can define how information is disseminated and received. 
        </p>
        <p>
            With COVID-19 as an active public health crisis in the United States, we thought there would be a bounty of data to study and learn from. Instead of opting for exclusively quantitative data, however, we discussed the non-traditional ways public health is enforced, like through speech. Acute to this class, the three of us all approached the third assignment with sentiment analysis or related goals and we wanted to continue on that path for this final project. We also felt the baseline of this approach would be flexibility enough so as to draw on any number of scopes. 
        </p>
        
        <h3>Project Objectives</h3>
        <p>
            A tool that allows users to compare the language around COVID-19 by geographic scope, profession, date, and intended audience.
        </p>
        <h4>Sample framing questions:</h4>
        <ul>
            <li>How does the language of X politician compare from March 2020 to November 2020
            <li>How does a layman’s language differ from an expert’s
            <li>How does information compare when intended for a general audience versus a medical audience 
            <li>How do local politicians discuss COVID against federally elected/serving government officials 
            <li>Regionally, how is information shared to a general audience for news consumption? 
            <li>How does language relate to COVID cases 
        </ul>
        
        <h3>Data</h3>
        <p>
            As the project develops, we’ll decide whether or not we want to rely more on manually entered transcripts or on APIs. Since this is just meant to give an overview of each source’s discussions of COVID, it’s not necessary to include every piece of communication as long as the samples are representative (although more is of course nice).
        </p>
        <h4>Manual Entry:</h4>
        <ul>
            <li>Presidential addresses and other white house correspondence transcripts are available publicly online
            <li>Same as above for news
            <li>Some scientific journals about COVID are freely available online as pdfs
            <li>Finding public correspondence from experts will probably be more challenging - one option is to manually scour other sources for interviews with doctors/scientists
        </ul>
        <h4>APIs/Comprehensive Data Sets:</h4>
        <ul>
            <li>Google has an <a href="https://newsapi.org/docs">API for searching news</a> to supplement manual entries
            <li>This <a href="http://wordlist.aspell.net/">spellchecking data set</a> has word lists broken down by nationality (American, British, etc), word rarity (as a substitute for complexity), and various types of speech
            <li>This <a href="https://www.kaggle.com/kkhandekar/word-difficulty">word complexity data set</a>
            <li>Twitter API for someone’s (cough Trump’s) tweets
        </ul>
        
        <h3>Data Processing</h3>
        <p>
            Accumulating and processing the data will probably be a large part of the project. We assume there won’t be APIs for everything we want, so we’re going to need to manually collect text samples from various sources. This will take some legwork, but we also have APIs and we’re just looking for a representative sample - it shouldn’t matter much if we don’t have an enormous wealth of data. Manually entered data will need manually entered metadata for our filtering. This metadata will include (when applicable/available) date published, location, who said it (probably broken up into categories like news anchor, politician, doctor, scientist), and so on. We’ll also need to write code to find this metadata in any data gathered live from an API. Depending on what analysis we decide to do, we might also want to remove articles and other junk words. Once we have the data, we need some way to quantify it. The spellchecking/word complexity data sets include several useful metrics, but we might also want to design COVID-specific ones (for example, how often does “vaccine,” “mask,” “school,” or a synonym of “hoax” appear?). Two of our group members did something similar to this for assignment 3, and the third has other experience with language processing. We also want to leverage other peoples’ work as much as possible, so we’ll probably also use a sentiment analysis library (or something similar) to get useful quantitative data from the text.
        </p>
        
        <h3>Visualization Design</h3>
        <h3>Brainstorming:</h3>
        <img src="img/IMG_2144.jpeg" width="500" height="625"/>
        <img src="img/IMG_2138.jpeg" width="500" height="625"/>
        <p>
            In order to organize our thoughts, we started by listing out the variables we'd potentially like to work
            with. After this, it became clear that there were two main approaches: create one main visualization with 
            lots of toggle options, or create several smaller visualizations. The design challenge of this project was 
            to find a middle ground where the user would not be overwhelmed by the large amounts of data.
        </p>
        <h3>Initial Designs:</h3>
        <img src="img/IMG_2139.jpeg" width="450" height="550"/>
        <img src="img/IMG_2140.jpeg" width="450" height="550"/>
        <img src="img/IMG_2142.jpeg" width="450" height="550"/>
        <p>
            Each of the inital designs seemed to naturally build off of each other rather than being completely distinct. The design took on three stages:
            <h4>Design 1:</h4>
            <ul> 
                <li>Observed how multiple independent visualizations would look on a page.</li>
                <li>Visualizations:
                    <ul>
                        <li>Hoverable graph of COVID cases over time that could display the most commonly used words during different time periods.</li>
                        <li>Generic scatter plot that would let the user pick two variables for the x- and y-axes. The plotted points would be media sources.</li>
                        <li>A general "grab bag" of buzz words and concepts that are often used in COVID communication. A user would select a category 
                            (e.g. left-leaning articles) and see which words/concepts communicators most often would choose from the "grab bag." This allows users 
                            to see information that is typically left out in addition to what is used.
                        </li>
                    </ul>
                </li>
            </ul>
            <h4>Design 2:</h4>
            <ul> 
                <li>Started to experiment with connected visualizations and focused more on side-by-side comparisons.</li>
                <li>Visualizations:
                    <ul>
                        <li>COVID case graph in this design serves more as a tool to adjust the main visualization, and does not do any text analysis in itself.</li>
                        <li>Word map uses high-frequency words from a selected category (e.g. medical journals, local news articles) and connects them to words often used in their proximity 
                            (whether that is in the same sentence or same article is TBD). Stronger connections would be displayed as either bolder or shorter lines and higher-frequency words as bolder nodes. 
                            The user would then be able to drag the map across the line barrier to see a new selected category. The words NOT used by the new category would drop to the corner of the original box. 
                            This would highlight differences between the two categories.
                        </li>
                        <li>Two generic bar charts undernear the focal point visualization provide additional information about the average conciseness and complexity of the language used in those categories. 
                            Conciseness would be measured as a ratio of verbs:adjectives and complexity would require an outside dataset (mentioned in the Data section).
                        </li>
                    </ul>
                </li>
            </ul>
            <h4>Design 3:</h4>
            <ul> 
                <li>Increased interactivity and interdependence of visualizations.</li>
                <li>Visualizations:
                    <ul>
                        <li>Top COVID case graph still allows users to change visualization data, but also includes on-hover tooltips.</li>
                        <li>Word map (see Design 2). The only difference here would be an additional feature to click on words to render the third visualization.</li>
                        <li>Sentiment analysis graph of the use of a particular word (selected from the word map) over time.</li>
                    </ul>
                </li>
            </ul>
        </p>
        <h3>Realization Design:</h3>
        <img src="img/IMG_2143.jpeg" width="500" height="625"/>
        <h4>Features:</h4>
        <ul>
            <li>COVID case graph still functions as way to manipulate word map as well as having some additional info on hover.</li>
            <li>Category selection becomes more of a focal point within its own block of the page rather than within the word map boxes.</li>
            <li>
                Word map (same as Design 3). However, this map will include a grayed-out "ghost" of the previous map after it is dragged 
                across the barrier.
            </li>
            <li>
                Sentiment map based on selected word similar to Design 3, except it is compatible with two separate categories for comparison. 
                Each category's graph can be toggled on/off for clarity as well.
            </li>
        </ul>
        <h4>Design Justification:</h4>
        <p>
            Our design is meant to shed light on how COVID communication differs across various audiences, platforms, and communicators. During the current 
            pandemic, trillions of sources reach the general public. This visualization should allow users to unpack the undertones and objectives of this surplus of information 
            in order to detect biases and find what is most reliable and relevant.
        </p>
        <ul>
            <li>
                We wanted to emphasize how communication shifted over time, as a result of spikes in cases or times of relative calm, to reveal different sources' underlying motivations. 
                By placing our timeline at the very top of the page, this emphasizes to users that time plays a large part.
            </li>
            <li>
                In Design 2, we decided to emphasize comparison between source categories, so the final design made the selection of categories to compare more of a focal point. This also makes it clearer 
                to the user that both the word maps AND sentiment graph would be using those category selections.
            </li>
            <li>
                For means of comparison, we wanted to depict which words certain sources did not include compared to others. However, the lines linking the words in the map also change from 
                category to category. Knowing this, we decided to incorporate a "ghost map" in each visualization box so users could also compare how word connections differed between sources. 
                The "fit block into X-shaped hole" children's toy inspired this approach. Whenever the map was dragged across the barrier, users could see what information was pruned/readjusted in 
                order to resemble the ghost map of the other category.
            </li>
            <li>
                In order to give users flexibility to either observe more general trends or dive into more specific information, we made the word map serve as a way of selecting values for the sentiment graph. 
                This seemed less overwhelming to the user and made the visualization appear more cohesive than disjointed.
            </li>
            <li>
                Continuing with the side-by-side comparison theme, we adjusted the sentiment map to display two categories at once and toggle the display. This provides more insight into how 
                different source categories handled similar scenarios over time.
            </li>
        </ul>

        <h3>Must-Have Features</h3>
        <ul>
            <li>The ability to compare at least two reference texts from different sources side by side
            <li>At least three forms of analysis offered for the comparison (sentiment analysis, word frequency, etc.)
            <li>Texts ranging from just before COVID-19 was declared a pandemic to present for accuracy 
            <li>Data reflecting the voices of: elected officials, journalists, health professionals to have a range of intended audiences 
        </ul>
        
        <h3>Optional Features</h3>
        <ul>
            <li>Integration of a news API to provide up-to-date analysis 
            <li>Filter data first by keywords or other data tags to refine comparisons 
            <li>Allow for users to compare multiple documents by multiple focuses/categories 
            <li>Allow for users to extrapolate analysis from particular selection(s) of a text(s)
        </ul>
        
        <h3>Project Schedule</h3>
        <h5>November 15-21</h5>
        <ul>
            <li>Define small data set and perform analysis testing 
            <li>Generate sample visualizations from dataset 
            <li>Start data acquisition & tag texts 
        </ul>
        <h5>November 22-28</h5>
        <ul>
            <li>Finishing data acquisition & tag texts 
            <li>Drafting designs and sketch layout of site 
            <li>Make data visualization extensible for different texts 
            <li>Integrate further sentiment analysis/on-call comparisons 
        </ul>
        <h5>November 29-December 5</h5>
        <ul>
            <li>Finish basic components of data analysis and visualization 
            <li>Integrate all data streams into analysis tools and render visuals 
        </ul>
        <h5>December 6-12</h5>
        <ul>
            <li>Catch up week for blockers or final aspects of basic components 
            <li>Refine UI and integrate data analysis/impact from visualizations 
        </ul>
        <h5>December 13-19</h5>
        <ul>
            <li>Refine website and polish basic components of project 
            <li>Get feedback from professors and begin work on additional features 
        </ul>
        
        
    </body>
</html>
